# Introduction

Welcome to CustomRAG local LLM Modeling tool. This repo helps you create your own LLM RAG model in minutes.

# Intended user
    - Anyone with personal/organisational data
    - Anyone who want's to run it locally

# Before Getting Started:
    - install ollama in system
    - run ollama application 
    - ollama pull <model>
        e.g. ollama pull llama2

# Getting Started:
    - install python ( version: 3.11)
    - create virtual environment 
        python -m venv venv
    - load requirements
        pip install -r requirements.txt
    - run tool
        python CustomRAG.py -c examples/askGITA/config.yaml

# Pending task:
    - Write Testcases
    - Create Documentation (sphrinx)