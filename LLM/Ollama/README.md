Welcome to COnfigureable LLM Model. This repo helps you create your own LLM RAG model in minutes.

Intended user: 
    - Anyone with personal/orginasational data
    - Anyone who want's to run it locally

Before Getting Started:
    - install ollama in system
    - ollama pull <model>
        ollama pull llama2

Getting Started:
    - install python ( version: )
    - create virtual environment 
        python -m venv venv
    - load requirements
        pip install -r requirements.txt
    - run main.py
        python main.py

Pending task:
    - Enable Linting
    - Write Testcases
    - create  pipeline
    - Create Documentation (sphrinx)
    - Write Medium article